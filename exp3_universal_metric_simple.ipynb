{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e2063b",
   "metadata": {},
   "source": [
    "# More systematic analysis: how to calculate \"effective depth\"\n",
    "\n",
    "Here we analyze and plot the results of effective depth across different models. We follow \"Do Language Models Use Their Depth Efficiently?\" by Csord√°s et al. (2025) and use the following metrics:\n",
    "1. Relative norm contribution & cosine similarity\n",
    "2. The effects of the layer on future computations\n",
    "3. Logit lens overlap\n",
    "4. Residual erasure experiment\n",
    "5. Integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2670e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d1f25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    # 1.5B models\n",
    "    \"DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    \"Qwen2.5-1.5B-Instruct\",\n",
    "    \"Qwen2.5-Math-1.5B\",\n",
    "    # 7B models\n",
    "    \"DeepSeek-R1-Distill-Qwen-7B\",\n",
    "    \"Qwen2.5-7B-Instruct\",\n",
    "    \"Qwen2.5-Math-7B\",\n",
    "    # 14B models\n",
    "    \"DeepSeek-R1-Distill-Qwen-14B\",\n",
    "    \"Qwen2.5-14B-Instruct\",\n",
    "    \"Qwen2.5-14B\",\n",
    "    # 32B models\n",
    "    \"DeepSeek-R1-Distill-Qwen-32B\",\n",
    "    \"Qwen2.5-32B-Instruct\",\n",
    "    \"Qwen2.5-32B\"\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e165c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ed_cosine_similarity(att_cos, mlp_cos, layer_cos):\n",
    "    '''\n",
    "    Calculate the effective depth through cosine similarity metric.\n",
    "    '''\n",
    "    mean_effect = torch.mean(torch.stack([att_cos, mlp_cos, layer_cos]), dim=0)\n",
    "    ll = []\n",
    "    for l in range(mean_effect.shape[0]-1):\n",
    "        if mean_effect[l] < 0 and mean_effect[l + 1] >= 0:\n",
    "            ll.append(l)\n",
    "    return ll[-1]\n",
    "\n",
    "def calc_ed_logitlens_kl(res_kl_divs, threshold=0.1):\n",
    "    '''\n",
    "    Calculate the effective depth through logit lens KL divergence metric.\n",
    "    '''\n",
    "    layer = res_kl_divs.shape[0]\n",
    "    for l in range(layer - 1):\n",
    "        if res_kl_divs[l] < threshold * res_kl_divs.max():\n",
    "            return l\n",
    "    return -1\n",
    "\n",
    "def calc_ed_logitlens_overlap(res_overlap, threshold=0.2):\n",
    "    '''\n",
    "    Calculate the effective depth through logit lens overlap metric.\n",
    "    '''\n",
    "    layer = res_overlap.shape[0]\n",
    "    for l in range(layer - 1):\n",
    "        if res_overlap[l] > threshold:\n",
    "            return l\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating All Metrics:\n",
      "Model                          @ Dataset   : ED (cos) ED (KL)  ED (Overlap)\n",
      "--------------------------------------------------------------------------------\n",
      "DeepSeek-R1-Distill-Qwen-1.5B  @ hellaswag : 17(0.64) 20(0.75) 23(0.86)\n",
      "DeepSeek-R1-Distill-Qwen-1.5B  @ gsm8k     : 16(0.61)  1(0.07) 23(0.86)\n",
      "DeepSeek-R1-Distill-Qwen-1.5B  @ aime24    : 17(0.64) 24(0.89) 24(0.89)\n",
      "Qwen2.5-1.5B-Instruct          @ hellaswag : 16(0.61) 21(0.79) 23(0.86)\n",
      "Qwen2.5-1.5B-Instruct          @ gsm8k     : 20(0.75) 22(0.82) 23(0.86)\n",
      "Qwen2.5-1.5B-Instruct          @ aime24    : 19(0.71) 23(0.86) 23(0.86)\n",
      "Qwen2.5-Math-1.5B              @ hellaswag : 16(0.61) 20(0.75) 23(0.86)\n",
      "Qwen2.5-Math-1.5B              @ gsm8k     : 16(0.61) 22(0.82) 23(0.86)\n",
      "Qwen2.5-Math-1.5B              @ aime24    : 16(0.61) 23(0.86) 23(0.86)\n",
      "DeepSeek-R1-Distill-Qwen-7B    @ hellaswag : 16(0.61) 24(0.89) 25(0.93)\n",
      "DeepSeek-R1-Distill-Qwen-7B    @ gsm8k     : 16(0.61) 24(0.89) 25(0.93)\n",
      "DeepSeek-R1-Distill-Qwen-7B    @ aime24    : 16(0.61) 24(0.89) 24(0.89)\n",
      "Qwen2.5-7B-Instruct            @ hellaswag : 17(0.64) 25(0.93) 26(0.96)\n",
      "Qwen2.5-7B-Instruct            @ gsm8k     : 20(0.75) 25(0.93) 26(0.96)\n",
      "Qwen2.5-7B-Instruct            @ aime24    : 18(0.68) 25(0.93) 26(0.96)\n",
      "Qwen2.5-Math-7B                @ hellaswag : 16(0.61) 23(0.86) 24(0.89)\n",
      "Qwen2.5-Math-7B                @ gsm8k     : 11(0.43) 23(0.86) 24(0.89)\n",
      "Qwen2.5-Math-7B                @ aime24    : 16(0.61) 23(0.86) 24(0.89)\n",
      "DeepSeek-R1-Distill-Qwen-14B   @ hellaswag : 26(0.56) 40(0.85) 44(0.94)\n",
      "DeepSeek-R1-Distill-Qwen-14B   @ gsm8k     : 30(0.65) 39(0.83) 44(0.94)\n",
      "DeepSeek-R1-Distill-Qwen-14B   @ aime24    : 30(0.65) 41(0.88) 44(0.94)\n",
      "Qwen2.5-14B-Instruct           @ hellaswag : 27(0.58) 40(0.85) 45(0.96)\n",
      "Qwen2.5-14B-Instruct           @ gsm8k     : 32(0.69) 41(0.88) 45(0.96)\n",
      "Qwen2.5-14B-Instruct           @ aime24    : 30(0.65) 42(0.90) 45(0.96)\n",
      "Qwen2.5-14B                    @ hellaswag : 27(0.58) 40(0.85) 45(0.96)\n",
      "Qwen2.5-14B                    @ gsm8k     : 30(0.65) 40(0.85) 45(0.96)\n",
      "Qwen2.5-14B                    @ aime24    : 30(0.65) 42(0.90) 45(0.96)\n",
      "DeepSeek-R1-Distill-Qwen-32B   @ hellaswag : 42(0.67) 58(0.92) 61(0.97)\n",
      "DeepSeek-R1-Distill-Qwen-32B   @ gsm8k     : 42(0.67) 55(0.88) 58(0.92)\n",
      "DeepSeek-R1-Distill-Qwen-32B   @ aime24    : 46(0.73) 57(0.91) 58(0.92)\n",
      "Qwen2.5-32B-Instruct           @ hellaswag : 43(0.69) 60(0.95) 61(0.97)\n",
      "Qwen2.5-32B-Instruct           @ gsm8k     : 46(0.73) 58(0.92) 60(0.95)\n",
      "Qwen2.5-32B-Instruct           @ aime24    : 43(0.69) 58(0.92) 60(0.95)\n",
      "Qwen2.5-32B                    @ hellaswag : 43(0.69) 60(0.95) 61(0.97)\n",
      "Qwen2.5-32B                    @ gsm8k     : 46(0.73) 57(0.91) 59(0.94)\n",
      "Qwen2.5-32B                    @ aime24    : 46(0.73) 59(0.94) 60(0.95)\n",
      "\n",
      "Results saved to effective_depth_results.xlsx\n",
      "\n",
      "Excel Table Preview:\n",
      "                                 cosine                                 \\\n",
      "                              hellaswag       gsm8k       aime24         \n",
      "                                     ED RATIO    ED RATIO     ED RATIO   \n",
      "DeepSeek-R1-Distill-Qwen-1.5B        17  0.64    16  0.61     17  0.64   \n",
      "Qwen2.5-1.5B-Instruct                16  0.61    20  0.75     19  0.71   \n",
      "Qwen2.5-Math-1.5B                    16  0.61    16  0.61     16  0.61   \n",
      "DeepSeek-R1-Distill-Qwen-7B          16  0.61    16  0.61     16  0.61   \n",
      "Qwen2.5-7B-Instruct                  17  0.64    20  0.75     18  0.68   \n",
      "\n",
      "                                     kl                                 \\\n",
      "                              hellaswag       gsm8k       aime24         \n",
      "                                     ED RATIO    ED RATIO     ED RATIO   \n",
      "DeepSeek-R1-Distill-Qwen-1.5B        20  0.75     1  0.07     24  0.89   \n",
      "Qwen2.5-1.5B-Instruct                21  0.79    22  0.82     23  0.86   \n",
      "Qwen2.5-Math-1.5B                    20  0.75    22  0.82     23  0.86   \n",
      "DeepSeek-R1-Distill-Qwen-7B          24  0.89    24  0.89     24  0.89   \n",
      "Qwen2.5-7B-Instruct                  25  0.93    25  0.93     25  0.93   \n",
      "\n",
      "                                overlap                                 \n",
      "                              hellaswag       gsm8k       aime24        \n",
      "                                     ED RATIO    ED RATIO     ED RATIO  \n",
      "DeepSeek-R1-Distill-Qwen-1.5B        23  0.86    23  0.86     24  0.89  \n",
      "Qwen2.5-1.5B-Instruct                23  0.86    23  0.86     23  0.86  \n",
      "Qwen2.5-Math-1.5B                    23  0.86    23  0.86     23  0.86  \n",
      "DeepSeek-R1-Distill-Qwen-7B          25  0.93    25  0.93     24  0.89  \n",
      "Qwen2.5-7B-Instruct                  26  0.96    26  0.96     26  0.96  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "\n",
    "def calculate_all_metrics(models: List[str]) -> Dict[str, Dict]:\n",
    "    results = {}\n",
    "    datasets = [\"hellaswag\", \"gsm8k\", \"aime24\"]\n",
    "    \n",
    "    print(f\"{'Model':30s} @ {'Dataset':10s}: {'ED (cos)':8s} {'ED (KL)':8s} {'ED (Overlap)':8s}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for model in models:\n",
    "        results[model] = {}\n",
    "        for dataset in datasets:\n",
    "            try:\n",
    "                model_results = {}\n",
    "                \n",
    "                try:\n",
    "                    cos_path = f\"outputs/{dataset}/{model}/relative_contribution.pt\"\n",
    "                    cos_data = torch.load(cos_path)\n",
    "                    att_cos = cos_data[\"att_cos\"]\n",
    "                    mlp_cos = cos_data[\"mlp_cos\"]\n",
    "                    layer_cos = cos_data[\"layer_cos\"]\n",
    "                    ed_cos = calc_ed_cosine_similarity(att_cos, mlp_cos, layer_cos)\n",
    "                    layer_cos_count = att_cos.shape[0]\n",
    "                    ratio_cos = (ed_cos + 1) / layer_cos_count\n",
    "                    model_results.update({\n",
    "                        f\"cosine_ed\": ed_cos,\n",
    "                        f\"cosine_ratio\": ratio_cos,\n",
    "                        f\"cosine_layers\": layer_cos_count\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"  Cosine error for {model} @ {dataset}: {e}\")\n",
    "                    model_results.update({\n",
    "                        f\"cosine_ed\": None,\n",
    "                        f\"cosine_ratio\": None,\n",
    "                        f\"cosine_layers\": None\n",
    "                    })\n",
    "                \n",
    "                try:\n",
    "                    if dataset == \"aime24\":\n",
    "                        logit_path = f\"outputs/{dataset}/{model}/logitlens_5exps.pt\"\n",
    "                    else:\n",
    "                        logit_path = f\"outputs/{dataset}/{model}/logitlens_10exps.pt\"\n",
    "                    logit_data = torch.load(logit_path)\n",
    "                    res_kl_divs = logit_data[\"res_kl_divs\"]\n",
    "                    ed_kl = calc_ed_logitlens_kl(res_kl_divs, threshold=0.5)\n",
    "                    layer_kl = res_kl_divs.shape[0]\n",
    "                    ratio_kl = (ed_kl + 1) / layer_kl\n",
    "                    model_results.update({\n",
    "                        f\"kl_ed\": ed_kl,\n",
    "                        f\"kl_ratio\": ratio_kl,\n",
    "                        f\"kl_layers\": layer_kl\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"  LogitLens KL error for {model} @ {dataset}: {e}\")\n",
    "                    model_results.update({\n",
    "                        f\"kl_ed\": None,\n",
    "                        f\"kl_ratio\": None,\n",
    "                        f\"kl_layers\": None\n",
    "                    })\n",
    "                \n",
    "                try:\n",
    "                    if dataset == \"aime24\":\n",
    "                        logit_path = f\"outputs/{dataset}/{model}/logitlens_5exps.pt\"\n",
    "                    else:\n",
    "                        logit_path = f\"outputs/{dataset}/{model}/logitlens_10exps.pt\"\n",
    "                    logit_data = torch.load(logit_path)\n",
    "                    res_overlaps = logit_data[\"res_overlaps\"]\n",
    "                    ed_overlap = calc_ed_logitlens_overlap(res_overlaps, threshold=0.3)\n",
    "                    layer_overlap = res_overlaps.shape[0]\n",
    "                    ratio_overlap = (ed_overlap + 1) / layer_overlap\n",
    "                    model_results.update({\n",
    "                        f\"overlap_ed\": ed_overlap,\n",
    "                        f\"overlap_ratio\": ratio_overlap,\n",
    "                        f\"overlap_layers\": layer_overlap\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"  LogitLens Overlap error for {model} @ {dataset}: {e}\")\n",
    "                    model_results.update({\n",
    "                        f\"overlap_ed\": None,\n",
    "                        f\"overlap_ratio\": None,\n",
    "                        f\"overlap_layers\": None\n",
    "                    })\n",
    "                \n",
    "                for key, value in model_results.items():\n",
    "                    results[model][f\"{dataset}_{key}\"] = value\n",
    "                \n",
    "                cos_str = f\"{ed_cos:2d}({ratio_cos:.2f})\" if model_results['cosine_ed'] is not None else \"N/A\"\n",
    "                kl_str = f\"{ed_kl:2d}({ratio_kl:.2f})\" if model_results['kl_ed'] is not None else \"N/A\"\n",
    "                overlap_str = f\"{ed_overlap:2d}({ratio_overlap:.2f})\" if model_results['overlap_ed'] is not None else \"N/A\"\n",
    "                \n",
    "                print(f\"{model:30s} @ {dataset:10s}: {cos_str:8s} {kl_str:8s} {overlap_str:8s}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Major error processing {model} @ {dataset}: {e}\")\n",
    "                # ‰∏∫Ëøô‰∏™datasetÊ∑ªÂä†Á©∫ÂÄº\n",
    "                for metric in ['cosine', 'kl', 'overlap']:\n",
    "                    for suffix in ['_ed', '_ratio', '_layers']:\n",
    "                        results[model][f\"{dataset}_{metric}{suffix}\"] = None\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_excel_table(results: Dict[str, Dict], output_file: str = \"effective_depth_results.xlsx\"):\n",
    "    \n",
    "    datasets = [\"hellaswag\", \"gsm8k\", \"aime24\"]\n",
    "    metrics = ['cosine', 'kl', 'overlap']\n",
    "    value_types = ['ed', 'ratio']\n",
    "    \n",
    "    columns = []\n",
    "    for metric in metrics:\n",
    "        for dataset in datasets:\n",
    "            for value_type in value_types:\n",
    "                columns.append((metric, dataset, value_type.upper()))\n",
    "    \n",
    "    df = pd.DataFrame(index=list(results.keys()), columns=pd.MultiIndex.from_tuples(columns))\n",
    "    \n",
    "    for model in results:\n",
    "        for dataset in datasets:\n",
    "            for metric in metrics:\n",
    "                for value_type in value_types:\n",
    "                    key = f\"{dataset}_{metric}_{value_type}\"\n",
    "                    value = results[model].get(key, None)\n",
    "                    df.loc[model, (metric, dataset, value_type.upper())] = value\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col[2] == 'RATIO':\n",
    "            df[col] = df[col].apply(lambda x: round(x, 2) if isinstance(x, (int, float)) else x)\n",
    "    \n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, sheet_name='Effective Depth Results')\n",
    "        \n",
    "        info_df = pd.DataFrame({\n",
    "            'Metric': ['cosine', 'kl', 'overlap'],\n",
    "            'Description': [\n",
    "                'Cosine Similarity based effective depth',\n",
    "                'LogitLens KL divergence based effective depth',\n",
    "                'LogitLens Overlap based effective depth'\n",
    "            ],\n",
    "            'Format': ['ED(Ratio)', 'ED(Ratio)', 'ED(Ratio)']\n",
    "        })\n",
    "        info_df.to_excel(writer, sheet_name='Description', index=False)\n",
    "    \n",
    "    print(f\"\\nResults saved to {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Calculating All Metrics:\")\n",
    "all_results = calculate_all_metrics(models)\n",
    "\n",
    "df = create_excel_table(all_results)\n",
    "\n",
    "print(\"\\nExcel Table Preview:\")\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
